{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#sklearn生态\n",
    "#sk辅助\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "#sk模型\n",
    "from sklearn.linear_model import Ridge\n",
    " \n",
    "\n",
    "\n",
    "#models \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as ctb\n",
    "\n",
    "#torch生态\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader as DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mae指标\n",
    "def get_mae(pred,true):\n",
    "    pred_ = []\n",
    "    true_ = []\n",
    "    for item in pred:\n",
    "        pred_.append(np.e**item -1)\n",
    "    for item in true:\n",
    "        true_.append(np.e**item -1)\n",
    "    return mae(true_,pred_)\n",
    "\n",
    "\n",
    "\n",
    "#临时score，不带入sigma的指标，后续会删除该函数\n",
    "def score_temp(y_true, y_pred, sigma = 200):\n",
    "    result = []\n",
    "    if len(y_true) != len(y_pred):\n",
    "        return print('size error')\n",
    "    sq2 = np.sqrt(2.)\n",
    "    for i in range(len(y_true)):\n",
    "        gap = abs(y_true[i] - y_pred[i])\n",
    "        metric = (gap / sigma)*sq2 + np.log(sigma* sq2)\n",
    "        result.append(metric)\n",
    "    return np.mean(result)\n",
    "\n",
    "#score越小越好\n",
    "def score (y_true, y_pred, confindience):\n",
    "    result = []\n",
    "    sq2 = np.sqrt(2.)\n",
    "    if len(y_true) != len(y_pred) or len(y_true) != len(confindience):\n",
    "        return print('size error')\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        sigma = max(70,confindience[i])\n",
    "        gap = min(1000,abs(y_true[i] - y_pred[i]))\n",
    "        metric = (gap / sigma)*sq2 + np.log(sigma* sq2)\n",
    "        result.append(metric)\n",
    "    return np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/train.csv')\n",
    "test_data = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/test.csv')\n",
    "submission = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集中没有女性，测试集中不存在SmokingStatus == 'Currently smokes'的数据，删除训练集中这样的数据\n",
    "train_data = train_data[train_data.Sex == 'Male']\n",
    "train_data = train_data[train_data.SmokingStatus != 'Currently smokes']\n",
    "#训练集数据去重\n",
    "train_data.drop_duplicates(keep='first', inplace=True, subset=['Patient','Weeks'])\n",
    "#所以训练集，测试集相应的特征也不需要了\n",
    "del train_data['Sex']\n",
    "del test_data['Sex']\n",
    "\n",
    "\n",
    "#重新命名，整理训练集，测试集的特征名称\n",
    "train_data.columns = ['patient','week','FVC','percent','age','SmokingStatus']\n",
    "test_data.columns = ['patient','base_week','base_FVC','percent','age','SmokingStatus']\n",
    "submission['predict_week'] = submission['Patient_Week'].apply(lambda x: int(x.split('_')[1]))\n",
    "submission['patient'] = submission['Patient_Week'].apply(lambda x: x.split('_')[0])\n",
    "\n",
    "#类别特征数值化\n",
    "train_data['SmokingStatus'] = train_data['SmokingStatus'].apply(lambda x : 0 if x == 'Ex-smoker' else 1)\n",
    "test_data['SmokingStatus'] = test_data['SmokingStatus'].apply(lambda x : 0 if x == 'Ex-smoker' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造测试集\n",
    "test_data = submission.drop(columns=['FVC', 'Confidence']).merge(test_data, on='patient')\n",
    "test_data['gap_week'] = test_data['predict_week'] - test_data['base_week']\n",
    "del test_data['predict_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造训练集\n",
    "temp = pd.DataFrame()\n",
    "for _, data_data in tqdm(train_data.groupby('patient')):\n",
    "    data_temp = pd.DataFrame()\n",
    "    for week, data_data_data in data_data.groupby('week'):\n",
    "        data_data_data_temp = data_data_data.drop(columns = 'age')\n",
    "        data_data_data_temp.columns = ['patient','base_week','base_FVC','base_percent','SmokingStatus']\n",
    "        del data_data_data_temp['SmokingStatus']\n",
    "        data_temp_ = data_data.merge(data_data_data_temp, on = 'patient')\n",
    "        data_temp = pd.concat([data_temp,data_temp_],axis = 0)\n",
    "    temp = pd.concat([temp,data_temp], axis = 0)  \n",
    "del train_data\n",
    "train_data = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['gap_week'] = train_data['week'] - train_data['base_week']\n",
    "del train_data['week']\n",
    "del train_data['base_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patient_info = [x for x in test_data['Patient_Week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#删除无用的column\n",
    "del train_data['patient']\n",
    "del train_data['percent']\n",
    "del test_data['Patient_Week']\n",
    "del test_data['patient']\n",
    "del test_data['base_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#整理训练集和测试集，使其columns名称一致\n",
    "test_data.columns = ['base_FVC','base_percent','age','SmokingStatus','gap_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#改变训练集特征的顺序，使其和测试集特征的顺序一致。\n",
    "train_data_FVC = train_data['FVC']\n",
    "train_data.drop(labels=['FVC'], axis=1, inplace = True)\n",
    "train_data.insert(5, 'FVC', train_data_FVC)\n",
    "\n",
    "train_data_base_FVC = train_data['base_FVC']\n",
    "train_data.drop(labels=['base_FVC'], axis=1, inplace = True)\n",
    "train_data.insert(0, 'base_FVC', train_data_base_FVC)\n",
    "\n",
    "train_data_base_percent = train_data['base_percent']\n",
    "train_data.drop(labels=['base_percent'], axis=1, inplace = True)\n",
    "train_data.insert(1, 'base_percent', train_data_base_percent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重设训练集和测试集的index\n",
    "train_data = train_data.reset_index()\n",
    "test_data = test_data.reset_index()\n",
    "\n",
    "#删除预测FVC == base_FVC的数据\n",
    "train_data = train_data.drop(train_data[train_data['gap_week'] == 0].index,axis = 0)\n",
    "del train_data['index']\n",
    "del test_data['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_data, test_data],axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#组合特征\n",
    "for i in tqdm(['base_FVC','base_percent','age','gap_week']):\n",
    "    for j in ['base_FVC','base_percent','age','gap_week']:\n",
    "        if i != j:\n",
    "            column_name = '{}_{}_multi'.format(i,j)\n",
    "            all_data[column_name] = all_data[i] * np.max(all_data[j]) + all_data[j]\n",
    "            column_name = '{}_{}divi'.format(i,j)\n",
    "            all_data[column_name] = (all_data[i] / all_data[j]).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#暂时不进行数据归一化，模型如需要再单独做归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_data[0:8994]\n",
    "test_data = all_data[8994:len(all_data)]\n",
    "train_y = train_data['FVC'].values\n",
    "del train_data['FVC']\n",
    "train_x = train_data.values\n",
    "del test_data['FVC']\n",
    "test_x = test_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理一下预测值的偏度\n",
    "train_y = np.log1p(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型部分\n",
    "#调参的代码就不放上来了，没啥意义，而且很多调试过的代码我都删掉了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "models = []\n",
    "valid_gap = [0 for _ in range(len(train_y))]\n",
    "models_weight = []\n",
    "for cnt, (tr_idx, val_idx) in tqdm(enumerate(kf.split(train_x)), total=5):\n",
    "    print('---------------FOLD:{} START----------------'.format(cnt))\n",
    "    kfold_train_x = train_x[tr_idx]\n",
    "    kfold_train_y = train_y[tr_idx]\n",
    "    kfold_valid_x = train_x[val_idx]\n",
    "    kfold_valid_y = train_y[val_idx]\n",
    "    #训练fold模型\n",
    "    model_lgb = lgb.LGBMRegressor(objective='regression', \n",
    "                              metric='mse',\n",
    "                                  \n",
    "                              learning_rate=0.01,\n",
    "                              n_estimators=637,\n",
    "                              max_depth =4, \n",
    "                              num_leaves  = 10,\n",
    "                               \n",
    "\n",
    "                              feature_fraction = 0.6,\n",
    "                              subsample = 0.7,\n",
    "                              subsample_freq = 7,\n",
    "\n",
    "                              min_child_samples=122,\n",
    "                              min_split_gain=0,\n",
    "                              min_child_weight=0,\n",
    "\n",
    "                              reg_alpha =0.001,\n",
    "                              reg_lambda = 2\n",
    "                             )\n",
    "    model_lgb.fit(X=kfold_train_x, \n",
    "                  y=kfold_train_y, \n",
    "                  eval_set=[(kfold_train_x, kfold_train_y), (kfold_valid_x, kfold_valid_y)],\n",
    "                  eval_names=['train loss', 'valid loss'], \n",
    "                  eval_metric='mse',\n",
    "                  verbose=10,\n",
    "                  early_stopping_rounds=300,\n",
    "                  )\n",
    "    valid_predict = np.array(model_lgb.predict(kfold_valid_x))\n",
    "    \n",
    "    errors = []\n",
    "    for i in range(len(valid_predict)):\n",
    "        predict_ = np.e ** valid_predict[i] -1\n",
    "        true_ = np.e ** kfold_valid_y[i] -1\n",
    "        gap_ = abs(predict_ - true_)\n",
    "        errors.append(gap_)\n",
    "        \n",
    "    for i in range(len(errors)):\n",
    "        index = val_idx[i]\n",
    "        valid_gap[index] = errors[i]\n",
    "    models_weight.append(1/np.mean(valid_gap))\n",
    "        \n",
    "    models.append(model_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_weight = [x/np.sum(models_weight) for x in models_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predict = [0 for _ in range(len(test_x))]\n",
    "for index in range(len(models)):\n",
    "    model = models[index]\n",
    "    predict = model.predict(test_x)\n",
    "    for i in range(len(test_x)):\n",
    "        all_predict[i] += predict[i] * 0.2 #models_weight[index]\n",
    "        \n",
    "\n",
    "all_predict = [np.e**x-1 for x in all_predict]\n",
    "\n",
    "submission = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/sample_submission.csv')\n",
    "pred_info = [x for x in submission['Patient_Week']]\n",
    "result = [0 for _ in range(len(submission))]\n",
    "\n",
    "for i in range(len(submission)):\n",
    "    pred = all_predict[i]\n",
    "    target = test_patient_info[i]\n",
    "    \n",
    "    index = pred_info.index(target)\n",
    "    result[index] = pred\n",
    "\n",
    "submission['FVC'] = result\n",
    "submission['Confidence'] = 200\n",
    "submission.to_csv('submission_lgb.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里存在一个小问题，临时模型的名称还是lgb，实际上是xgb。因为这块的代码是我从上面lgb直接copy过来的，临时名称懒得改了。\n",
    "#如果做工程，需要写个函数，统一一下，会规范很多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "models = []\n",
    "valid_gap = [0 for _ in range(len(train_y))]\n",
    "models_weight = []\n",
    "for cnt, (tr_idx, val_idx) in tqdm(enumerate(kf.split(train_x)), total=5):\n",
    "    print('---------------FOLD:{} START----------------'.format(cnt))\n",
    "    kfold_train_x = train_x[tr_idx]\n",
    "    kfold_train_y = train_y[tr_idx]\n",
    "    kfold_valid_x = train_x[val_idx]\n",
    "    kfold_valid_y = train_y[val_idx]\n",
    "    #训练fold模型\n",
    "    model_lgb = xgb.XGBRegressor(random_state  = 2020,\n",
    "                             booster='gbtree',\n",
    "                             \n",
    "                             learning_rate = 0.01,\n",
    "                             n_estimators = 780,\n",
    "                             \n",
    "                             max_depth = 5,\n",
    "                             \n",
    "                             colsample_bytree = 0.5,\n",
    "                             colsample_bylevel =0.8,\n",
    "                             colsample_bynode= 1.0,\n",
    "                             subsample = 0.4,\n",
    "                             \n",
    "                             gamma = 0.09,\n",
    "                             min_child_weight = 80,\n",
    "                             \n",
    "                             \n",
    "                             reg_alpha = 0.01,\n",
    "                             reg_lambda = 3\n",
    "\n",
    "\n",
    "                                )\n",
    "    model_lgb.fit(X=kfold_train_x, \n",
    "                  y=kfold_train_y, \n",
    "                  eval_set=[(kfold_train_x,kfold_train_y),(kfold_valid_x, kfold_valid_y)],\n",
    "                  \n",
    "                  \n",
    "                  verbose=10,\n",
    "                  early_stopping_rounds=300,\n",
    "                  )\n",
    "    valid_predict = np.array(model_lgb.predict(kfold_valid_x))\n",
    "    \n",
    "    errors = []\n",
    "    for i in range(len(valid_predict)):\n",
    "        predict_ = np.e ** valid_predict[i] -1\n",
    "        true_ = np.e ** kfold_valid_y[i] -1\n",
    "        gap_ = abs(predict_ - true_)\n",
    "        errors.append(gap_)\n",
    "        \n",
    "    for i in range(len(errors)):\n",
    "        index = val_idx[i]\n",
    "        valid_gap[index] = errors[i]\n",
    "    models_weight.append(1/np.mean(valid_gap))\n",
    "        \n",
    "    models.append(model_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_weight = [x/np.sum(models_weight) for x in models_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predict = [0 for _ in range(len(test_x))]\n",
    "for index in range(len(models)):\n",
    "    model = models[index]\n",
    "    predict = model.predict(test_x)\n",
    "    for i in range(len(test_x)):\n",
    "        all_predict[i] += predict[i] * 0.2 #models_weight[index]\n",
    "        \n",
    "\n",
    "all_predict = [np.e**x-1 for x in all_predict]\n",
    "\n",
    "submission = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/sample_submission.csv')\n",
    "pred_info = [x for x in submission['Patient_Week']]\n",
    "result = [0 for _ in range(len(submission))]\n",
    "\n",
    "for i in range(len(submission)):\n",
    "    pred = all_predict[i]\n",
    "    target = test_patient_info[i]\n",
    "    \n",
    "    index = pred_info.index(target)\n",
    "    result[index] = pred\n",
    "\n",
    "submission['FVC'] = result\n",
    "submission['Confidence'] = 200\n",
    "submission.to_csv('submission_xtb.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "models = []\n",
    "valid_gap = [0 for _ in range(len(train_y))]\n",
    "models_weight = []\n",
    "for cnt, (tr_idx, val_idx) in tqdm(enumerate(kf.split(train_x)), total=5):\n",
    "    print('---------------FOLD:{} START----------------'.format(cnt))\n",
    "    kfold_train_x = train_x[tr_idx]\n",
    "    kfold_train_y = train_y[tr_idx]\n",
    "    kfold_valid_x = train_x[val_idx]\n",
    "    kfold_valid_y = train_y[val_idx]\n",
    "    #训练fold模型\n",
    "    model_ctb = ctb.CatBoostRegressor(random_state = 2020,\n",
    "    \n",
    "                                  learning_rate=0.01,\n",
    "                                  \n",
    "                                  n_estimators = 576,\n",
    "                                  depth = 5,\n",
    "                                  \n",
    "\n",
    "                                  colsample_bylevel = 0.4,\n",
    "                                  subsample = 0.3,\n",
    "                                  bagging_temperature = 0.5,\n",
    "                                  \n",
    "                                  min_child_samples = 0,\n",
    "                                  \n",
    "                                  reg_lambda = 17.4,\n",
    "                                  \n",
    "                                  \n",
    "\n",
    "                                 )\n",
    "    model_ctb.fit(X=kfold_train_x, \n",
    "                  y=kfold_train_y, \n",
    "                  eval_set=[(kfold_train_x,kfold_train_y),(kfold_valid_x, kfold_valid_y)],\n",
    "                  \n",
    "                  \n",
    "                  verbose=10,\n",
    "                  early_stopping_rounds=300,\n",
    "                  )\n",
    "    valid_predict = np.array(model_ctb.predict(kfold_valid_x))\n",
    "    \n",
    "    errors = []\n",
    "    for i in range(len(valid_predict)):\n",
    "        predict_ = np.e ** valid_predict[i] -1\n",
    "        true_ = np.e ** kfold_valid_y[i] -1\n",
    "        gap_ = abs(predict_ - true_)\n",
    "        errors.append(gap_)\n",
    "        \n",
    "    for i in range(len(errors)):\n",
    "        index = val_idx[i]\n",
    "        valid_gap[index] = errors[i]\n",
    "    models_weight.append(1/np.mean(valid_gap))\n",
    "        \n",
    "    models.append(model_ctb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_weight = [x/np.sum(models_weight) for x in models_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predict = [0 for _ in range(len(test_x))]\n",
    "for index in range(len(models)):\n",
    "    model = models[index]\n",
    "    predict = model.predict(test_x)\n",
    "    for i in range(len(test_x)):\n",
    "        all_predict[i] += predict[i] * 0.2 #models_weight[index]\n",
    "        \n",
    "\n",
    "all_predict = [np.e**x-1 for x in all_predict]\n",
    "\n",
    "submission = pd.read_csv('../input/osic-pulmonary-fibrosis-progression/sample_submission.csv')\n",
    "pred_info = [x for x in submission['Patient_Week']]\n",
    "result = [0 for _ in range(len(submission))]\n",
    "\n",
    "for i in range(len(submission)):\n",
    "    pred = all_predict[i]\n",
    "    target = test_patient_info[i]\n",
    "    \n",
    "    index = pred_info.index(target)\n",
    "    result[index] = pred\n",
    "\n",
    "submission['FVC'] = result\n",
    "submission['Confidence'] = 200\n",
    "submission.to_csv('submission_ctb.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最终的提交结果是几个模型预测结果的线性融合，融合的系数的调试没有技术含量 ，就不放上来了。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
